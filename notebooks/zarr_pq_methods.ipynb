{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import itertools\n",
    "import sys\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_pq(pq_list, the_type):\n",
    "    '''\n",
    "    function to process a list of pq files and return appropriate\n",
    "    3D coordinates\n",
    "    '''\n",
    "\n",
    "    keys = {\n",
    "        \"condensed\": 0,\n",
    "        \"condensed_edge\": 1,\n",
    "        \"condensed_env\": 2,\n",
    "        \"condensed_shell\": 3,\n",
    "        \"core\": 4,\n",
    "        \"core_edge\": 5,\n",
    "        \"core_env\": 6,\n",
    "        \"core_shell\": 7,\n",
    "        \"plume\": 8,\n",
    "        }\n",
    "\n",
    "    # to get both the full domain of x and y along with the x and y coordinates\n",
    "    # for the given type (condensed, core, etc.)\n",
    "\n",
    "    full = defaultdict(list)\n",
    "    sub = defaultdict(list)\n",
    "    extrema = defaultdict(list)\n",
    "    for f in pq_list:\n",
    "        table = pq.read_table(f).to_pandas()\n",
    "        c_id = table['cloud_id'].values[0]\n",
    "        if the_type == 'full' or the_type == 'base':\n",
    "            tablerows = table['type'] == keys[\"condensed\"]\n",
    "        else:\n",
    "            tablerows = table['type'] == keys[the_type]\n",
    "        df_thetype = table[tablerows]\n",
    "        for dimension in ['x', 'y', 'z']:\n",
    "            for suffix in ['full', 'sub']:\n",
    "                if suffix == 'full':\n",
    "                    full[(dimension, suffix)].append(table[dimension].values)\n",
    "                else:\n",
    "                    sub[(dimension, suffix)].append(df_thetype[dimension].values)\n",
    "            for suffix in ['min', 'max']:\n",
    "                if suffix == 'min':\n",
    "                    extrema[(dimension, suffix)].append(np.amin(table[dimension].values))\n",
    "                    sub[(dimension, suffix)].append(np.amin(df_thetype[dimension].values))\n",
    "                else:\n",
    "                    extrema[(dimension, suffix)].append(np.amax(table[dimension].values))\n",
    "                    sub[(dimension, suffix)].append(np.amax(table[dimension].values))\n",
    "    return full, sub, c_id, extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/datatmp/visualize/andrew/bomex_json_files/16936.json\n",
      "16936\n"
     ]
    }
   ],
   "source": [
    "filename = '/mnt/datatmp/visualize/andrew/bomex_json_files/16936.json'\n",
    "tracktype = 'condensed'\n",
    "varname = 'QN'\n",
    "meters2km = 1.e-3\n",
    "print(filename)\n",
    "with open(filename, 'r') as f:\n",
    "    files = json.load(f)\n",
    "num_ts = len(files['pq_filenames'])\n",
    "pq_filelist = sorted(files['pq_filenames'])\n",
    "\n",
    "fulldict, subdict, cloud_id, extdict = process_pq(pq_filelist, tracktype)\n",
    "\n",
    "print(cloud_id)\n",
    "\n",
    "min_x, max_x = np.amin(extdict[('x', 'min')]), np.amax(extdict[('x', 'max')])\n",
    "min_y, max_y = np.amax(extdict[('y', 'min')]), np.amax(extdict[('x', 'max')])\n",
    "\n",
    "# to handle the cases where the cloud crosses a boundary\n",
    "domain = 256\n",
    "\n",
    "x = np.array(list(itertools.chain.from_iterable(fulldict[('x', 'full')])))\n",
    "y = np.array(list(itertools.chain.from_iterable(fulldict[('y', 'full')])))\n",
    "# hardcoded for bomex currently\n",
    "off_x = 0\n",
    "off_y = 0\n",
    "if (max_x - min_x) > (domain / 2):\n",
    "    off_x = domain - np.min(x[(x > domain / 2)])\n",
    "if (max_y - min_y) > (domain / 2):\n",
    "    off_y = domain - np.min(y[(y > domain / 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 256, 256)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/mini36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2855: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "for t_step, the_file in enumerate(files['var_filenames']):\n",
    "    the_in = zarr.open_group(the_file, mode='r')\n",
    "    try:\n",
    "        # startx, stopx = x_indices[0], x_indices[1]\n",
    "        # starty, stopy = y_indices[0], y_indices[1]\n",
    "        # extra slice 0 is there to remove the time dimension from the zarr data\n",
    "        var_data = the_in[varname][:][0]\n",
    "        x_r = subdict[('x', 'sub')][t_step]\n",
    "        y_r = subdict[('y', 'sub')][t_step]\n",
    "        z = subdict[('z', 'sub')][t_step]\n",
    "        if off_x > 0:\n",
    "            var_data = np.roll(var_data, off_x, axis=2)\n",
    "            x_r = x_r + off_x\n",
    "            x_r[x_r > domain - 1] = x_r[x_r > domain - 1] - domain - 1\n",
    "        if off_y > 0:\n",
    "            var_data = np.roll(var_data, off_y, axis=1)\n",
    "            y_r = y_r + off_y\n",
    "            y_r[y_r > domain - 1] = y_r[y_r > domain - 1] - domain - 1\n",
    "        # only map the values that are valid for the given type\n",
    "        indices = np.array((z, y_r, x_r))\n",
    "        b_map = np.zeros_like(var_data, dtype=bool)\n",
    "        if tracktype == 'full':\n",
    "            b_map[:] = True\n",
    "        elif tracktype == 'base':\n",
    "            z_base = subdict[('z', 'min')][t_step]\n",
    "            b_map[z_base, y_r, x_r] = True\n",
    "        else:\n",
    "            b_map[tuple(indices)] = True\n",
    "        var_data[~b_map] = 0\n",
    "        var_data = np.ma.masked_values(var_data, 0)\n",
    "        var_data = var_data[:, :, :]\n",
    "        print(var_data.shape)\n",
    "        sys.exit(0)\n",
    "    except KeyError:\n",
    "        print('variable names are: ', write_error(the_in))\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
